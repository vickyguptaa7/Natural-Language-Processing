{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte Pair Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "For a given text corpus ‘C’, perform the following step to implement BPE\n",
    "- STEP 1: Add end of the word char ‘<\\w’ at the end of each word. Add spaces between the characters of each word.\n",
    "- STEP 2 : Find word frequencies, character frequencies (in the form of dictionary)\n",
    "- STEP 3: For a predefined no. of iterations X, perform the following:\n",
    "-   STEP 3a: Find the pair of most frequent consecutive characters\n",
    "Pfreq .\n",
    "-   STEP 3b: Merge the pair of characters in Pfreq , and save it as\n",
    "rule no. ‘i’.\n",
    "-   STEP 3c: Update word frequency, and character frequency dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low', 'lowest', 'newer', 'wider', 'new']\n",
      "['l', 'o', 'w', ' ', 'l', 'o', 'w', 'e', 's', 't', ' ', 'n', 'e', 'w', 'e', 'r', ' ', 'w', 'i', 'd', 'e', 'r', ' ', 'n', 'e', 'w']\n"
     ]
    }
   ],
   "source": [
    "str=\"low lowest newer wider new\"\n",
    "words = word_tokenize(str)\n",
    "print(words)\n",
    "print([*str]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['l', 'o', 'w', '<\\\\w'], ['l', 'o', 'w', 'e', 's', 't', '<\\\\w'], ['n', 'e', 'w', 'e', 'r', '<\\\\w'], ['w', 'i', 'd', 'e', 'r', '<\\\\w'], ['n', 'e', 'w', '<\\\\w']]\n",
      "{'l': 2, 'o': 2, 'w': 5, '<\\\\w': 5, 'e': 5, 's': 1, 't': 1, 'n': 2, 'r': 2, 'i': 1, 'd': 1}\n"
     ]
    }
   ],
   "source": [
    "words_freq=[]\n",
    "characters_freq={}\n",
    "\n",
    "def preprocessing(words,words_freq, characters_freq):\n",
    "    for i in range(len(words)):\n",
    "        word_split=[*words[i]];\n",
    "        word_split.append('<\\w');\n",
    "        words_freq.append(word_split);\n",
    "        for i in range(len(word_split)):\n",
    "            if word_split[i] in characters_freq:\n",
    "                characters_freq[word_split[i]]+=1\n",
    "            else:   \n",
    "                characters_freq[word_split[i]]=1 \n",
    "\n",
    "preprocessing(words,words_freq,characters_freq)\n",
    "print(words_freq)\n",
    "print(characters_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_most_freq_words=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_consecutive_characters(words_freq):\n",
    "    consec_freq={}\n",
    "    for i in range(len(words_freq)):\n",
    "        for j in range(1,len(words_freq[i])):\n",
    "            # print(i,j,words_freq[i])\n",
    "            consec=words_freq[i][j-1]+words_freq[i][j];\n",
    "            if consec in consec_freq:\n",
    "                consec_freq[consec]+=1\n",
    "            else:\n",
    "                consec_freq[consec]=1;\n",
    "    mx_freq=0\n",
    "    target=\"\"\n",
    "    print(consec_freq);\n",
    "    for key in consec_freq:\n",
    "        if mx_freq<consec_freq[key]:\n",
    "            mx_freq=consec_freq[key]\n",
    "            target=key\n",
    "\n",
    "    return target        \n",
    "\n",
    "\n",
    "# print(find_most_consecutive_characters(words_freq));\n",
    "\n",
    "def merge_most_freq_consecutive_characters(target,words_freq):\n",
    "    training_most_freq_words.append(target);\n",
    "    print(\"merge character : \",target)\n",
    "    isMerged=False;\n",
    "    for i in range(len(words_freq)):\n",
    "        new_words_freq=[]\n",
    "        \n",
    "        iter=1;\n",
    "        while iter<len(words_freq[i]):\n",
    "            consec=words_freq[i][iter-1]+words_freq[i][iter];\n",
    "            if consec == target:\n",
    "                isMerged=True;\n",
    "                new_words_freq.append(target)\n",
    "                iter+=1\n",
    "            else:\n",
    "                new_words_freq.append(words_freq[i][iter-1])\n",
    "            iter+=1\n",
    "        \n",
    "        if iter==len(words_freq[i]):\n",
    "            new_words_freq.append(words_freq[i][iter-1]);\n",
    "        words_freq[i]=new_words_freq\n",
    "    return words_freq,isMerged\n",
    "\n",
    "# print(merge_most_freq_consecutive_characters(words_freq));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTIAL WORD FREQUENCY :  [['l', 'o', 'w', '<\\\\w'], ['l', 'o', 'w', 'e', 's', 't', '<\\\\w'], ['n', 'e', 'w', 'e', 'r', '<\\\\w'], ['w', 'i', 'd', 'e', 'r', '<\\\\w'], ['n', 'e', 'w', '<\\\\w']] \n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  1 \n",
      "\n",
      "{'lo': 2, 'ow': 2, 'w<\\\\w': 2, 'we': 2, 'es': 1, 'st': 1, 't<\\\\w': 1, 'ne': 2, 'ew': 2, 'er': 2, 'r<\\\\w': 2, 'wi': 1, 'id': 1, 'de': 1}\n",
      "merge character :  lo\n",
      "WORD FREQUENCY :  [['lo', 'w', '<\\\\w'], ['lo', 'w', 'e', 's', 't', '<\\\\w'], ['n', 'e', 'w', 'e', 'r', '<\\\\w'], ['w', 'i', 'd', 'e', 'r', '<\\\\w'], ['n', 'e', 'w', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  2 \n",
      "\n",
      "{'low': 2, 'w<\\\\w': 2, 'we': 2, 'es': 1, 'st': 1, 't<\\\\w': 1, 'ne': 2, 'ew': 2, 'er': 2, 'r<\\\\w': 2, 'wi': 1, 'id': 1, 'de': 1}\n",
      "merge character :  low\n",
      "WORD FREQUENCY :  [['low', '<\\\\w'], ['low', 'e', 's', 't', '<\\\\w'], ['n', 'e', 'w', 'e', 'r', '<\\\\w'], ['w', 'i', 'd', 'e', 'r', '<\\\\w'], ['n', 'e', 'w', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  3 \n",
      "\n",
      "{'low<\\\\w': 1, 'lowe': 1, 'es': 1, 'st': 1, 't<\\\\w': 1, 'ne': 2, 'ew': 2, 'we': 1, 'er': 2, 'r<\\\\w': 2, 'wi': 1, 'id': 1, 'de': 1, 'w<\\\\w': 1}\n",
      "merge character :  ne\n",
      "WORD FREQUENCY :  [['low', '<\\\\w'], ['low', 'e', 's', 't', '<\\\\w'], ['ne', 'w', 'e', 'r', '<\\\\w'], ['w', 'i', 'd', 'e', 'r', '<\\\\w'], ['ne', 'w', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  4 \n",
      "\n",
      "{'low<\\\\w': 1, 'lowe': 1, 'es': 1, 'st': 1, 't<\\\\w': 1, 'new': 2, 'we': 1, 'er': 2, 'r<\\\\w': 2, 'wi': 1, 'id': 1, 'de': 1, 'w<\\\\w': 1}\n",
      "merge character :  new\n",
      "WORD FREQUENCY :  [['low', '<\\\\w'], ['low', 'e', 's', 't', '<\\\\w'], ['new', 'e', 'r', '<\\\\w'], ['w', 'i', 'd', 'e', 'r', '<\\\\w'], ['new', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  5 \n",
      "\n",
      "{'low<\\\\w': 1, 'lowe': 1, 'es': 1, 'st': 1, 't<\\\\w': 1, 'newe': 1, 'er': 2, 'r<\\\\w': 2, 'wi': 1, 'id': 1, 'de': 1, 'new<\\\\w': 1}\n",
      "merge character :  er\n",
      "WORD FREQUENCY :  [['low', '<\\\\w'], ['low', 'e', 's', 't', '<\\\\w'], ['new', 'er', '<\\\\w'], ['w', 'i', 'd', 'er', '<\\\\w'], ['new', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  6 \n",
      "\n",
      "{'low<\\\\w': 1, 'lowe': 1, 'es': 1, 'st': 1, 't<\\\\w': 1, 'newer': 1, 'er<\\\\w': 2, 'wi': 1, 'id': 1, 'der': 1, 'new<\\\\w': 1}\n",
      "merge character :  er<\\w\n",
      "WORD FREQUENCY :  [['low', '<\\\\w'], ['low', 'e', 's', 't', '<\\\\w'], ['new', 'er<\\\\w'], ['w', 'i', 'd', 'er<\\\\w'], ['new', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  7 \n",
      "\n",
      "{'low<\\\\w': 1, 'lowe': 1, 'es': 1, 'st': 1, 't<\\\\w': 1, 'newer<\\\\w': 1, 'wi': 1, 'id': 1, 'der<\\\\w': 1, 'new<\\\\w': 1}\n",
      "merge character :  low<\\w\n",
      "WORD FREQUENCY :  [['low<\\\\w'], ['low', 'e', 's', 't', '<\\\\w'], ['new', 'er<\\\\w'], ['w', 'i', 'd', 'er<\\\\w'], ['new', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  8 \n",
      "\n",
      "{'lowe': 1, 'es': 1, 'st': 1, 't<\\\\w': 1, 'newer<\\\\w': 1, 'wi': 1, 'id': 1, 'der<\\\\w': 1, 'new<\\\\w': 1}\n",
      "merge character :  lowe\n",
      "WORD FREQUENCY :  [['low<\\\\w'], ['lowe', 's', 't', '<\\\\w'], ['new', 'er<\\\\w'], ['w', 'i', 'd', 'er<\\\\w'], ['new', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  9 \n",
      "\n",
      "{'lowes': 1, 'st': 1, 't<\\\\w': 1, 'newer<\\\\w': 1, 'wi': 1, 'id': 1, 'der<\\\\w': 1, 'new<\\\\w': 1}\n",
      "merge character :  lowes\n",
      "WORD FREQUENCY :  [['low<\\\\w'], ['lowes', 't', '<\\\\w'], ['new', 'er<\\\\w'], ['w', 'i', 'd', 'er<\\\\w'], ['new', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  10 \n",
      "\n",
      "{'lowest': 1, 't<\\\\w': 1, 'newer<\\\\w': 1, 'wi': 1, 'id': 1, 'der<\\\\w': 1, 'new<\\\\w': 1}\n",
      "merge character :  lowest\n",
      "WORD FREQUENCY :  [['low<\\\\w'], ['lowest', '<\\\\w'], ['new', 'er<\\\\w'], ['w', 'i', 'd', 'er<\\\\w'], ['new', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def start_prog(words_freq,iter=5):\n",
    "    print(\"INTIAL WORD FREQUENCY : \",words_freq,\"\\n\\n\");\n",
    "    for i in range(iter):\n",
    "        print(\"-\"*100,\"\\n\",\"ITERATION : \",i+1,\"\\n\");\n",
    "        target=find_most_consecutive_characters(words_freq);\n",
    "        if len(target) == 0:\n",
    "            print(\"No more consecutive characters found!\")\n",
    "            print(\"-\"*100)\n",
    "            break;\n",
    "        words_freq,isMerged=merge_most_freq_consecutive_characters(target,words_freq);\n",
    "        print(\"WORD FREQUENCY : \",words_freq);\n",
    "        print(\"-\"*100)   \n",
    "\n",
    "start_prog(words_freq,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lo', 'low', 'ne', 'new', 'er', 'er<\\\\w', 'low<\\\\w', 'lowe', 'lowes', 'lowest']\n"
     ]
    }
   ],
   "source": [
    "print(training_most_freq_words);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence=\"lower\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lower']\n",
      "[['l', 'o', 'w', 'e', 'r', '<\\\\w']]\n",
      "{'l': 1, 'o': 1, 'w': 1, 'e': 1, 'r': 1, '<\\\\w': 1}\n"
     ]
    }
   ],
   "source": [
    "test_words = word_tokenize(test_sentence)\n",
    "print(test_words);\n",
    "\n",
    "test_words_freq=[]\n",
    "test_characters_freq={}\n",
    "preprocessing(test_words,test_words_freq,test_characters_freq)\n",
    "print(test_words_freq)\n",
    "print(test_characters_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTIAL WORD FREQUENCY :  [['l', 'o', 'w', 'e', 'r', '<\\\\w']] \n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  1 \n",
      "\n",
      "merge character :  lo\n",
      "WORD FREQUENCY :  [['lo', 'w', 'e', 'r', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  2 \n",
      "\n",
      "merge character :  low\n",
      "WORD FREQUENCY :  [['low', 'e', 'r', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  3 \n",
      "\n",
      "merge character :  ne\n",
      "Not Applicable!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  4 \n",
      "\n",
      "merge character :  new\n",
      "Not Applicable!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  5 \n",
      "\n",
      "merge character :  er\n",
      "WORD FREQUENCY :  [['low', 'er', '<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  6 \n",
      "\n",
      "merge character :  er<\\w\n",
      "WORD FREQUENCY :  [['low', 'er<\\\\w']]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  7 \n",
      "\n",
      "merge character :  low<\\w\n",
      "Not Applicable!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  8 \n",
      "\n",
      "merge character :  lowe\n",
      "Not Applicable!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  9 \n",
      "\n",
      "merge character :  lowes\n",
      "Not Applicable!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      " ITERATION :  10 \n",
      "\n",
      "merge character :  lowest\n",
      "Not Applicable!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def start_test(test_words_freq):\n",
    "    print(\"INTIAL WORD FREQUENCY : \",test_words_freq,\"\\n\\n\");\n",
    "    for i in range(len(training_most_freq_words)):\n",
    "        print(\"-\"*100,\"\\n\",\"ITERATION : \",i+1,\"\\n\");\n",
    "        target=training_most_freq_words[i];\n",
    "        test_words_freq,isMerged=merge_most_freq_consecutive_characters(target,test_words_freq);\n",
    "        if isMerged==False:\n",
    "            print(\"Not Applicable!\")\n",
    "            print(\"-\"*100)\n",
    "            continue;\n",
    "\n",
    "        print(\"WORD FREQUENCY : \",test_words_freq);\n",
    "        print(\"-\"*100)\n",
    "\n",
    "start_test(test_words_freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
