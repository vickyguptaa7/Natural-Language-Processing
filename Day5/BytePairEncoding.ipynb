{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte Pair Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "For a given text corpus ‘C’, perform the following step to implement BPE\n",
    "- STEP 1: Add end of the word char ‘<\\w’ at the end of each word. Add spaces between the characters of each word.\n",
    "- STEP 2 : Find word frequencies, character frequencies (in the form of dictionary)\n",
    "- STEP 3: For a predefined no. of iterations X, perform the following:\n",
    "-   STEP 3a: Find the pair of most frequent consecutive characters\n",
    "Pfreq .\n",
    "-   STEP 3b: Merge the pair of characters in Pfreq , and save it as\n",
    "rule no. ‘i’.\n",
    "-   STEP 3c: Update word frequency, and character frequency dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'hell']\n",
      "['H', 'e', 'l', 'l', 'o', ' ', 'h', 'e', 'l', 'l']\n"
     ]
    }
   ],
   "source": [
    "str=\"Hello hell\"\n",
    "words = word_tokenize(str)\n",
    "print(words)\n",
    "print([*str]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['H', 'e', 'l', 'l', 'o', '<\\\\w'], ['h', 'e', 'l', 'l', '<\\\\w']]\n",
      "{'H': 1, 'e': 2, 'l': 4, 'o': 1, '<\\\\w': 2, 'h': 1}\n"
     ]
    }
   ],
   "source": [
    "words_freq=[]\n",
    "characters_freq={}\n",
    "\n",
    "def preprocessing(words,words_freq, characters_freq):\n",
    "    for i in range(len(words)):\n",
    "        word_split=[*words[i]];\n",
    "        word_split.append('<\\w');\n",
    "        words_freq.append(word_split);\n",
    "        for i in range(len(word_split)):\n",
    "            if word_split[i] in characters_freq:\n",
    "                characters_freq[word_split[i]]+=1\n",
    "            else:   \n",
    "                characters_freq[word_split[i]]=1 \n",
    "\n",
    "preprocessing(words,words_freq,characters_freq)\n",
    "print(words_freq)\n",
    "print(characters_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_most_freq_words=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_consecutive_characters(words_freq):\n",
    "    consec_freq={}\n",
    "    for i in range(len(words_freq)):\n",
    "        for j in range(1,len(words_freq[i])):\n",
    "            # print(i,j,words_freq[i])\n",
    "            consec=words_freq[i][j-1]+words_freq[i][j];\n",
    "            if consec in consec_freq:\n",
    "                consec_freq[consec]+=1\n",
    "            else:\n",
    "                consec_freq[consec]=1;\n",
    "    mx_freq=0\n",
    "    target=\"\"\n",
    "    for key in consec_freq:\n",
    "        if mx_freq<consec_freq[key]:\n",
    "            mx_freq=consec_freq[key]\n",
    "            target=key\n",
    "\n",
    "    return target        \n",
    "\n",
    "\n",
    "# print(find_most_consecutive_characters(words_freq));\n",
    "\n",
    "def merge_most_freq_consecutive_characters(target,words_freq):\n",
    "    training_most_freq_words.append(target);\n",
    "    print(\"merge character : \",target)\n",
    "    isMerged=False;\n",
    "    for i in range(len(words_freq)):\n",
    "        new_words_freq=[]\n",
    "        \n",
    "        iter=1;\n",
    "        while iter<len(words_freq[i]):\n",
    "            consec=words_freq[i][iter-1]+words_freq[i][iter];\n",
    "            if consec == target:\n",
    "                isMerged=True;\n",
    "                new_words_freq.append(target)\n",
    "                iter+=1\n",
    "            else:\n",
    "                new_words_freq.append(words_freq[i][iter-1])\n",
    "            iter+=1\n",
    "        \n",
    "        if iter==len(words_freq[i]):\n",
    "            new_words_freq.append(words_freq[i][iter-1]);\n",
    "        words_freq[i]=new_words_freq\n",
    "    return words_freq,isMerged\n",
    "\n",
    "# print(merge_most_freq_consecutive_characters(words_freq));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['H', 'e', 'l', 'l', 'o', '<\\\\w'], ['h', 'e', 'l', 'l', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  el\n",
      "[['H', 'el', 'l', 'o', '<\\\\w'], ['h', 'el', 'l', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  ell\n",
      "[['H', 'ell', 'o', '<\\\\w'], ['h', 'ell', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  Hell\n",
      "[['Hell', 'o', '<\\\\w'], ['h', 'ell', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  Hello\n",
      "[['Hello', '<\\\\w'], ['h', 'ell', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  Hello<\\w\n",
      "[['Hello<\\\\w'], ['h', 'ell', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  hell\n",
      "[['Hello<\\\\w'], ['hell', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  hell<\\w\n",
      "[['Hello<\\\\w'], ['hell<\\\\w']] \n",
      "\n",
      "\n",
      "No more consecutive characters found!\n"
     ]
    }
   ],
   "source": [
    "def start_prog(words_freq,iter=5):\n",
    "    print(words_freq,\"\\n\\n\");\n",
    "    for i in range(iter):\n",
    "        target=find_most_consecutive_characters(words_freq);\n",
    "        if len(target) == 0:\n",
    "            print(\"No more consecutive characters found!\")\n",
    "            break;\n",
    "        words_freq,isMerged=merge_most_freq_consecutive_characters(target,words_freq);\n",
    "        print(words_freq,\"\\n\\n\");   \n",
    "\n",
    "start_prog(words_freq,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el', 'ell', 'Hell', 'Hello', 'Hello<\\\\w', 'hell', 'hell<\\\\w']\n"
     ]
    }
   ],
   "source": [
    "print(training_most_freq_words);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence=\"hello how are you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'how', 'are', 'you']\n",
      "[['h', 'e', 'l', 'l', 'o', '<\\\\w'], ['h', 'o', 'w', '<\\\\w'], ['a', 'r', 'e', '<\\\\w'], ['y', 'o', 'u', '<\\\\w']]\n",
      "{'h': 2, 'e': 2, 'l': 2, 'o': 3, '<\\\\w': 4, 'w': 1, 'a': 1, 'r': 1, 'y': 1, 'u': 1}\n"
     ]
    }
   ],
   "source": [
    "test_words = word_tokenize(test_sentence)\n",
    "print(test_words);\n",
    "\n",
    "test_words_freq=[]\n",
    "test_characters_freq={}\n",
    "preprocessing(test_words,test_words_freq,test_characters_freq)\n",
    "print(test_words_freq)\n",
    "print(test_characters_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge character :  el\n",
      "[['h', 'el', 'l', 'o', '<\\\\w'], ['h', 'o', 'w', '<\\\\w'], ['a', 'r', 'e', '<\\\\w'], ['y', 'o', 'u', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  ell\n",
      "[['h', 'ell', 'o', '<\\\\w'], ['h', 'o', 'w', '<\\\\w'], ['a', 'r', 'e', '<\\\\w'], ['y', 'o', 'u', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  Hell\n",
      "Not Applicable! \n",
      "\n",
      "\n",
      "merge character :  Hello\n",
      "Not Applicable! \n",
      "\n",
      "\n",
      "merge character :  Hello<\\w\n",
      "Not Applicable! \n",
      "\n",
      "\n",
      "merge character :  hell\n",
      "[['hell', 'o', '<\\\\w'], ['h', 'o', 'w', '<\\\\w'], ['a', 'r', 'e', '<\\\\w'], ['y', 'o', 'u', '<\\\\w']] \n",
      "\n",
      "\n",
      "merge character :  hell<\\w\n",
      "Not Applicable! \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def start_test(test_words_freq):\n",
    "    for i in range(len(training_most_freq_words)):\n",
    "        target=training_most_freq_words[i];\n",
    "        test_words_freq,isMerged=merge_most_freq_consecutive_characters(target,test_words_freq);\n",
    "        if isMerged==False:\n",
    "            print(\"Not Applicable!\",\"\\n\\n\")\n",
    "            continue;\n",
    "\n",
    "        print(test_words_freq,\"\\n\\n\");\n",
    "\n",
    "start_test(test_words_freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
