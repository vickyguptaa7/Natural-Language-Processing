{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67403f67",
   "metadata": {},
   "source": [
    "### Problem :- Scrape n documents of two categories from Wikipdia (say sports and education)\n",
    "\n",
    "- Preprocess and clean all the documents\n",
    "- Prepare \n",
    "    - Unigram count Matrix\n",
    "    - Bigram Probability Matrix\n",
    "    - TF-IDF Matrix\n",
    "- Apply appropriate Naive Bayes classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3de4c6-1c13-4303-b271-879a8037a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os.path as path\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d265f68-5b22-448c-a026-9b0de6ab92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1874ec3-594f-4d55-ae2c-b4c05a4098d5",
   "metadata": {},
   "source": [
    "### Fetch Scrape N documents of two categories from wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255f92b8-7ab6-4026-b664-13adf06fe45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS={\n",
    "    \"football\":[\"https://en.wikipedia.org/wiki/Football\",\"https://en.wikipedia.org/wiki/American_football\",\"https://en.wikipedia.org/wiki/Association_football\",\"https://en.wikipedia.org/wiki/Australian_rules_football\",\"https://en.wikipedia.org/wiki/Gaelic_football\"],\n",
    "    \"algorithm\":[\"https://en.wikipedia.org/wiki/Algorithm\",\"https://en.wikipedia.org/wiki/Analysis_of_algorithms\",\"https://en.wikipedia.org/wiki/Computational_complexity\",\"https://en.wikipedia.org/wiki/Worst-case_complexity\",\"https://en.wikipedia.org/wiki/Average-case_complexity\"],\n",
    "}\n",
    "BASE_URL=\"Documents\"\n",
    "stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', \n",
    "'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', \n",
    "'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n",
    " 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', \n",
    "'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', \n",
    "'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', \n",
    "'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \n",
    "'s', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y',\n",
    " 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", \n",
    "'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    " \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", \n",
    "'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22484d1",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "014abb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHTMLFromURL(url):\n",
    "    page = requests.get(url).content\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return soup;\n",
    "\n",
    "def getBodyTextFromHTML(soup):\n",
    "    paragraphs = soup.find_all('p')\n",
    "    text = '\\n'.join([para.get_text().strip() for para in paragraphs])\n",
    "    return text;\n",
    "\n",
    "def writeInTextFile(topic,filename,text):\n",
    "    file = open(path.join(BASE_URL,topic,filename),\"w\")\n",
    "    file.write(text)\n",
    "    file.close()\n",
    "\n",
    "def scrapeFunction():\n",
    "    for topic in URLS:\n",
    "        fileno=1;\n",
    "        for url in URLS[topic]:\n",
    "            soup = getHTMLFromURL(url)\n",
    "            text = getBodyTextFromHTML(soup)\n",
    "            filename = f\"{fileno}.txt\"\n",
    "            writeInTextFile(topic,filename,text)\n",
    "            print(\"Done for \",topic,filename)\n",
    "            fileno=fileno+1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db10002-b7ac-4294-8c30-1589d71e20d1",
   "metadata": {},
   "source": [
    "### Getting text from the urls provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72bdea19-b2c8-4e27-a296-af38eaf2d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for  football 1.txt\n",
      "Done for  football 2.txt\n",
      "Done for  football 3.txt\n",
      "Done for  football 4.txt\n",
      "Done for  football 5.txt\n",
      "Done for  algorithm 1.txt\n",
      "Done for  algorithm 2.txt\n",
      "Done for  algorithm 3.txt\n",
      "Done for  algorithm 4.txt\n",
      "Done for  algorithm 5.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scrapeFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a8a92",
   "metadata": {},
   "source": [
    "### Preperations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde54080",
   "metadata": {},
   "source": [
    "#### Unigram Count Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e064fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_set={}\n",
    "unique_word_dict={}\n",
    "\n",
    "def getUniqueWords(text):\n",
    "    unique_words={}\n",
    "    words = word_tokenize(text)\n",
    "    for word in words:\n",
    "        word=word.lower()\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        unique_word_set[word]=1\n",
    "        if word in unique_words:\n",
    "            unique_words[word]=unique_words[word]+1\n",
    "        else:\n",
    "            unique_words[word]=1\n",
    "    return unique_words;\n",
    "\n",
    "def getUniqueWordsFromFiles():\n",
    "    for topic in URLS:\n",
    "        if topic not in unique_word_dict:\n",
    "            unique_word_dict[topic]={}\n",
    "        for i in range(1,6):\n",
    "            filename = f\"{i}.txt\"\n",
    "            file = open(path.join(BASE_URL,topic,filename),\"r\")\n",
    "            text = file.read()\n",
    "            file.close()\n",
    "            unique_words=getUniqueWords(text);\n",
    "\n",
    "            for word in unique_words:\n",
    "                if word in unique_word_dict[topic]:\n",
    "                    unique_word_dict[topic][word]=unique_word_dict[topic][word]+unique_words[word]\n",
    "                else:\n",
    "                    unique_word_dict[topic][word]=1\n",
    "                    \n",
    "\n",
    "    print(\"Total Unique Words from files are \",len(unique_word_set))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66cbaa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Words from files are  6668\n"
     ]
    }
   ],
   "source": [
    "getUniqueWordsFromFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21cb70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           football  family   team  sports  involve       ,  varying  degrees  \\\n",
      "football      475.0     2.0  139.0    28.0      2.0  1593.0      2.0      3.0   \n",
      "algorithm       0.0     0.0    0.0     0.0      0.0   396.0      0.0      0.0   \n",
      "\n",
      "           kicking   ball  ...  good-on-average  weaker  1993  feigenbaum  \\\n",
      "football      38.0  214.0  ...              0.0     0.0   0.0         0.0   \n",
      "algorithm      0.0    0.0  ...              1.0     1.0   1.0         1.0   \n",
      "\n",
      "           fortnow  non-adaptive  reductions  2003  bogdanov  trevisan  \n",
      "football       0.0           0.0         0.0   0.0       0.0       0.0  \n",
      "algorithm      1.0           1.0         1.0   1.0       1.0       1.0  \n",
      "\n",
      "[2 rows x 6668 columns]\n"
     ]
    }
   ],
   "source": [
    "# for word in unique_word_set:\n",
    "#     print(\"word\",end=\"\\t\\t\")\n",
    "#     print(word,end=\"\\t\\t\");\n",
    "\n",
    "# print()\n",
    "\n",
    "# for topic in unique_word_dict:\n",
    "#     print(topic,end=\"\\t\")\n",
    "#     for word in unique_word_set:\n",
    "#         if word not in unique_word_dict[topic]:\n",
    "#             print(0,end=\"\\t\\t\")\n",
    "#         else:\n",
    "#             print(unique_word_dict[topic][word],end=\"\\t\\t\")\n",
    "#     print()\n",
    "\n",
    "df = pd.DataFrame(unique_word_dict)\n",
    "print(df.transpose().fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5dbba",
   "metadata": {},
   "source": [
    "#### Bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9bed29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_bigram_set={}\n",
    "unique_bigram_dict={}\n",
    "unique_bigram_length={}\n",
    "\n",
    "def getUniqueBigramsWords(text):\n",
    "    unique_words={}\n",
    "    words = word_tokenize(text)\n",
    "    prev=\"<string>\"\n",
    "    for word in words:\n",
    "        word=word.lower()\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        bigram=prev+\" \"+word\n",
    "        unique_bigram_set[bigram]=1\n",
    "        if bigram in unique_words:\n",
    "            unique_words[bigram]=unique_words[bigram]+1\n",
    "        else:\n",
    "            unique_words[bigram]=1\n",
    "        prev=word\n",
    "    return unique_words;\n",
    "\n",
    "\n",
    "def getUniqueBigramsFromFiles():\n",
    "    for topic in URLS:\n",
    "        if topic not in unique_bigram_length:\n",
    "                unique_bigram_length[topic]=0\n",
    "        if topic not in unique_bigram_dict:\n",
    "                unique_bigram_dict[topic]={}\n",
    "        for i in range(1,6):\n",
    "            filename = f\"{i}.txt\"\n",
    "            file = open(path.join(BASE_URL,topic,filename),\"r\")\n",
    "            text = file.read()\n",
    "            file.close()\n",
    "            unique_bigrams=getUniqueBigramsWords(text);\n",
    "            \n",
    "            for bigram in unique_bigrams:\n",
    "                if bigram in unique_bigram_dict[topic]:\n",
    "                    unique_bigram_dict[topic][bigram]=unique_bigram_dict[topic][bigram]+unique_bigrams[bigram]\n",
    "                else:\n",
    "                    unique_bigram_dict[topic][bigram]=1\n",
    "                \n",
    "                unique_bigram_length[topic]+=1;\n",
    "                    \n",
    "\n",
    "    print(\"Total Unique Words from files are \",len(unique_bigram_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce9e934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Words from files are  27228\n"
     ]
    }
   ],
   "source": [
    "getUniqueBigramsFromFiles();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f19ceae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;string&gt; football</th>\n",
       "      <th>football family</th>\n",
       "      <th>family team</th>\n",
       "      <th>team sports</th>\n",
       "      <th>sports involve</th>\n",
       "      <th>involve ,</th>\n",
       "      <th>, varying</th>\n",
       "      <th>varying degrees</th>\n",
       "      <th>degrees ,</th>\n",
       "      <th>, kicking</th>\n",
       "      <th>...</th>\n",
       "      <th>association made</th>\n",
       "      <th>made average-case</th>\n",
       "      <th>complexity via</th>\n",
       "      <th>via reductions</th>\n",
       "      <th>] literature</th>\n",
       "      <th>literature average</th>\n",
       "      <th>complexity includes</th>\n",
       "      <th>includes following</th>\n",
       "      <th>following work</th>\n",
       "      <th>work :</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>football</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           <string> football  football family  family team  team sports  \\\n",
       "football                 1.0              1.0          1.0          1.0   \n",
       "algorithm                0.0              0.0          0.0          0.0   \n",
       "\n",
       "           sports involve  involve ,  , varying  varying degrees  degrees ,  \\\n",
       "football              1.0        1.0        1.0              1.0        1.0   \n",
       "algorithm             0.0        0.0        0.0              0.0        0.0   \n",
       "\n",
       "           , kicking  ...  association made  made average-case  \\\n",
       "football         4.0  ...               0.0                0.0   \n",
       "algorithm        0.0  ...               1.0                1.0   \n",
       "\n",
       "           complexity via  via reductions  ] literature  literature average  \\\n",
       "football              0.0             0.0           0.0                 0.0   \n",
       "algorithm             1.0             1.0           1.0                 1.0   \n",
       "\n",
       "           complexity includes  includes following  following work  work :  \n",
       "football                   0.0                 0.0             0.0     0.0  \n",
       "algorithm                  1.0                 1.0             1.0     1.0  \n",
       "\n",
       "[2 rows x 27228 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# print(\"bigram\",end=\"\\t\\t\")\n",
    "# for bigram in unique_bigram_set:\n",
    "#     print(bigram,end=\"\\t\\t\");\n",
    "\n",
    "# print()\n",
    "\n",
    "# for topic in unique_bigram_dict:\n",
    "#     print(topic,end=\"\\t\")\n",
    "#     for bigram in unique_bigram_set:\n",
    "#         if bigram not in unique_bigram_dict[topic]:\n",
    "#             print(0,end=\"\\t\\t\")\n",
    "#         else:\n",
    "#             unique_bigram_dict[topic][bigram]=unique_bigram_dict[topic][bigram]/unique_bigram_length[topic]\n",
    "#             print(unique_bigram_dict[topic][bigram],end=\"\\t\\t\")\n",
    "#     print()\n",
    "\n",
    "df = pd.DataFrame(unique_bigram_dict)\n",
    "df.transpose().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36981336",
   "metadata": {},
   "source": [
    "### Bigram Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f88307",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_bigram_prob_dict={}\n",
    "for topic in unique_bigram_dict:\n",
    "    unique_bigram_prob_dict[topic]={}\n",
    "    for bigram in unique_bigram_set:\n",
    "        unique_bigram_prob_dict[topic][bigram]=0;\n",
    "        if bigram in unique_bigram_dict[topic]:\n",
    "            unique_bigram_prob_dict[topic][bigram]=unique_bigram_dict[topic][bigram]/unique_bigram_length[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21eeb76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;string&gt; football</th>\n",
       "      <th>football family</th>\n",
       "      <th>family team</th>\n",
       "      <th>team sports</th>\n",
       "      <th>sports involve</th>\n",
       "      <th>involve ,</th>\n",
       "      <th>, varying</th>\n",
       "      <th>varying degrees</th>\n",
       "      <th>degrees ,</th>\n",
       "      <th>, kicking</th>\n",
       "      <th>...</th>\n",
       "      <th>association made</th>\n",
       "      <th>made average-case</th>\n",
       "      <th>complexity via</th>\n",
       "      <th>via reductions</th>\n",
       "      <th>] literature</th>\n",
       "      <th>literature average</th>\n",
       "      <th>complexity includes</th>\n",
       "      <th>includes following</th>\n",
       "      <th>following work</th>\n",
       "      <th>work :</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>football</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           <string> football  football family  family team  team sports  \\\n",
       "football            0.000044         0.000044     0.000044     0.000044   \n",
       "algorithm           0.000000         0.000000     0.000000     0.000000   \n",
       "\n",
       "           sports involve  involve ,  , varying  varying degrees  degrees ,  \\\n",
       "football         0.000044   0.000044   0.000044         0.000044   0.000044   \n",
       "algorithm        0.000000   0.000000   0.000000         0.000000   0.000000   \n",
       "\n",
       "           , kicking  ...  association made  made average-case  \\\n",
       "football    0.000175  ...          0.000000           0.000000   \n",
       "algorithm   0.000000  ...          0.000109           0.000109   \n",
       "\n",
       "           complexity via  via reductions  ] literature  literature average  \\\n",
       "football         0.000000        0.000000      0.000000            0.000000   \n",
       "algorithm        0.000109        0.000109      0.000109            0.000109   \n",
       "\n",
       "           complexity includes  includes following  following work    work :  \n",
       "football              0.000000            0.000000        0.000000  0.000000  \n",
       "algorithm             0.000109            0.000109        0.000109  0.000109  \n",
       "\n",
       "[2 rows x 27228 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(unique_bigram_prob_dict)\n",
    "df.transpose().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da4b1f",
   "metadata": {},
   "source": [
    "### TF IDF Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b44ac7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_dict_tfidf={}\n",
    "unique_word_doc_count={}\n",
    "def getUniqueWordsFromFiles():\n",
    "    for topic in URLS:\n",
    "        unique_word_dict_tfidf[topic]={}\n",
    "        unique_word_doc_count[topic]={}\n",
    "        for i in range(1,6):\n",
    "            filename = f\"{i}.txt\"\n",
    "            file = open(path.join(BASE_URL,topic,filename),\"r\")\n",
    "            text = file.read()\n",
    "            file.close()\n",
    "            unique_words=getUniqueWords(text);\n",
    "            \n",
    "            unique_word_dict_tfidf[topic][i]={}\n",
    "            unique_word_doc_count[topic][i]=0\n",
    "\n",
    "            for word in unique_words:\n",
    "                unique_word_dict_tfidf[topic][i][word]=unique_words[word]\n",
    "                unique_word_doc_count[topic][i]+=unique_words[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75631a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mathematics</th>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bogdanov</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trevisan</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unlikely</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>association</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2608 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    1         2         3        4         5\n",
       "mathematics  0.001488  0.000000  0.000000  0.00000  0.000000\n",
       "computer     0.000000  0.000000  0.000000  0.00000  0.000000\n",
       "science      0.000063  0.000079  0.000048  0.00023  0.000000\n",
       ",            0.000000  0.000000  0.000000  0.00000  0.000000\n",
       "algorithm    0.000000  0.000000  0.000000  0.00000  0.000000\n",
       "...               ...       ...       ...      ...       ...\n",
       "2003         0.000000  0.000000  0.000000  0.00000  0.000512\n",
       "bogdanov     0.000000  0.000000  0.000000  0.00000  0.000512\n",
       "trevisan     0.000000  0.000000  0.000000  0.00000  0.000512\n",
       "unlikely     0.000000  0.000000  0.000000  0.00000  0.000512\n",
       "association  0.000000  0.000000  0.000000  0.00000  0.000512\n",
       "\n",
       "[2608 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getUniqueWordsFromFiles();\n",
    "\n",
    "for topic in unique_word_dict_tfidf:\n",
    "    for i in unique_word_dict_tfidf[topic]:\n",
    "        for word in unique_word_dict_tfidf[topic][i]:\n",
    "            total=len(unique_word_dict_tfidf[topic])\n",
    "            count=0\n",
    "            for j in unique_word_dict_tfidf[topic]:\n",
    "                if word in unique_word_dict_tfidf[topic][j]:\n",
    "                    count+=1\n",
    "            idf=math.log10(total/count)\n",
    "            tf=unique_word_dict_tfidf[topic][i][word]/unique_word_doc_count[topic][i]\n",
    "            unique_word_dict_tfidf[topic][i][word]=tf*idf;\n",
    "\n",
    "pd.DataFrame(unique_word_dict_tfidf['football']).fillna(0)\n",
    "pd.DataFrame(unique_word_dict_tfidf['algorithm']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac05832e",
   "metadata": {},
   "source": [
    "### Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "953e782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sentence=\"I like algorithms and football\"\n",
    "def removeStopWords(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    new_sentence=\"\"\n",
    "    for word in words:\n",
    "        if word.lower() not in stop_words:\n",
    "            new_sentence+=word+\" \"\n",
    "    return new_sentence;\n",
    "\n",
    "words=word_tokenize(removeStopWords(my_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f3a252d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football :  45.28292963730315\n",
      "Algorithm :  54.71707036269685\n"
     ]
    }
   ],
   "source": [
    "prob1=1\n",
    "prob2=1;\n",
    "total_word1=0;\n",
    "total_word2=0;\n",
    "\n",
    "for word in unique_word_dict['football']:\n",
    "    total_word1+=unique_word_dict['football'][word];\n",
    "\n",
    "for word in unique_word_dict['algorithm']:\n",
    "    total_word2+=unique_word_dict['algorithm'][word];\n",
    "\n",
    "for word in words:\n",
    "\n",
    "    # for class football\n",
    "    if word in unique_word_dict['football']:\n",
    "        prob1*=unique_word_dict['football'][word]/(total_word1);\n",
    "    else:\n",
    "        # laplace \n",
    "        prob1*=(1)/(len(unique_word_dict['football'])+total_word1)\n",
    "\n",
    "    # for class algorithm\n",
    "    if word in unique_word_dict['algorithm']:\n",
    "        prob2*=unique_word_dict['algorithm'][word]/(total_word2);\n",
    "    else:\n",
    "        # laplace \n",
    "        prob2*=(1)/(len(unique_word_dict['algorithm'])+total_word2)\n",
    "\n",
    "print('Football : ',(prob1/(prob1+prob2))*100)\n",
    "print('Algorithm : ',(prob2/(prob1+prob2))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
